import json
import asyncio
import os
import re
from pathlib import Path
from dotenv import load_dotenv
from llm import get_llm

# Carregar .env
load_dotenv()
llm = get_llm()

def extract_json(text: str):
    # Remove demarca√ß√£o de blocos ```json ... ```
    text = re.sub(r"```(?:json)?", "", text)
    text = text.replace("```", "")

    # Extrai o primeiro objeto JSON bem formado
    match = re.search(r"\{[\s\S]*\}", text)
    if not match:
        return None
    
    try:
        return json.loads(match.group(0))
    except Exception:
        return None

# -----------------------------------------------------------------------------
# UTILIT√ÅRIOS: carregar ruleset e helper para executar bloqueante no thread pool
# -----------------------------------------------------------------------------
def load_ruleset():
    path = Path(__file__).resolve().parent / "sprints" / "ruleset_sprint_planner_v1.md"
    if not path.exists():
        raise FileNotFoundError(f"Arquivo de regras n√£o encontrado: {path}")
    return path.read_text(encoding="utf-8")

async def run_blocking(func, *args, **kwargs):
    return await asyncio.to_thread(func, *args, **kwargs)

# -----------------------------------------------------------------------------
# Fun√ß√£o principal adaptada: usa llm.invoke() do ChatGoogleGenerativeAI
# -----------------------------------------------------------------------------
async def generate_tasks_with_gemini(user_stories: list[dict]):
    ruleset = load_ruleset()
    user_stories_json = json.dumps(user_stories, indent=2, ensure_ascii=False)

    prompt = f"""
Voc√™ deve seguir as regras do sistema abaixo e responder APENAS com um JSON no formato especificado:

### REGRAS_DO_SISTEMA:
{ruleset}

### INPUT:
{user_stories_json}

Lembre-se: retorne apenas um objeto JSON com chave "tasks" contendo a lista de tasks.
"""

    def call_llm_sync():
        resp = llm.invoke(prompt)

        if isinstance(resp, str):
            return resp
        if hasattr(resp, "content"):
            return resp.content
        if hasattr(resp, "message") and hasattr(resp.message, "content"):
            return resp.message.content
        
        return str(resp)

    raw_output = await run_blocking(call_llm_sync)

    data = extract_json(raw_output)
    if data is None:
        raise RuntimeError(
            "Erro ao interpretar sa√≠da do Gemini/LangChain como JSON.\n"
            f"Sa√≠da recebida:\n{raw_output}"
        )

    tasks = data.get("tasks", [])
    if not isinstance(tasks, list):
        raise ValueError("Formato inesperado: 'tasks' n√£o √© uma lista.")

    return tasks

async def replan_tasks_with_gemini(current_tasks, instruction):
    ruleset = load_ruleset()

    input_json = json.dumps({
        "instruction": instruction,
        "current_tasks": current_tasks
    }, ensure_ascii=False, indent=2)

    prompt = f"""
Voc√™ √© um planejador de sprint que deve **modificar** o sprint existente,
seguindo as regras do sistema e respeitando ao m√°ximo o trabalho j√° planejado.

### REGRAS DO SISTEMA
{ruleset}

### CONTEXTO PARA REPLANEJAMENTO
{input_json}

Sua tarefa:
- Ajustar, remover, adicionar ou reestimar tasks conforme a instru√ß√£o dada.
- Manter a coer√™ncia, consist√™ncia e granularidade do sprint j√° existente.
- Responder apenas com JSON no formato:
{{
  "tasks": [ ... ]
}}
"""

    def call_sync():
        resp = llm.invoke(prompt)
        if isinstance(resp, str):
            return resp
        if hasattr(resp, "content"):
            return resp.content
        if hasattr(resp, "message") and hasattr(resp.message, "content"):
            return resp.message.content
        return str(resp)

    raw_output = await run_blocking(call_sync)

    # üîπ Garante que sai JSON v√°lido
    data = extract_json(raw_output)
    if data is None:
        raise RuntimeError(f"Sa√≠da inv√°lida do Gemini/LangChain:\n{raw_output}")

    tasks = data.get("tasks", [])
    if not isinstance(tasks, list):
        raise ValueError(f"'tasks' n√£o √© lista:\n{data}")

    return tasks